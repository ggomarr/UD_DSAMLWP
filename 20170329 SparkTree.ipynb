{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Launching Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/home/ggomarr/.spark\n"
     ]
    }
   ],
   "source": [
    "%env SPARK_HOME=/home/ggomarr/.spark\n",
    "master_node='spark://Otter:7077'\n",
    "app_name='SparkTree'\n",
    "dataframeMode=True\n",
    "stopSpark=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.deploy.master.Master running as process 3733.  Stop it first.\n",
      "org.apache.spark.deploy.worker.Worker running as process 3793.  Stop it first.\n"
     ]
    }
   ],
   "source": [
    "!/home/ggomarr/.spark/sbin/start-master.sh\n",
    "!/home/ggomarr/.spark/sbin/start-slave.sh {master_node}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if dataframeMode:\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark=SparkSession.builder.master(master_node).appName(app_name).getOrCreate()\n",
    "    sc=spark.sparkContext\n",
    "else:\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "    conf=SparkConf().setMaster(master_node).setAppName(app_name)\n",
    "    sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test using a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, u'(Common Development and Distribution License (CDDL) v1.0) JavaBeans Activation Framework (JAF) (javax.activation:activation:1.1 - http://java.sun.com/products/javabeans/jaf/index.jsp)')\n",
      "(166, u'(COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.0) (GNU General Public Library) Streaming API for XML (javax.xml.stream:stax-api:1.0-2 - no url defined)')\n",
      "(142, u'(CDDL 1.0) Servlet Specification 2.5 API (org.mortbay.jetty:servlet-api-2.5:6.1.14 - http://jetty.mortbay.org/project/modules/servlet-api-2.5)')\n",
      "(126, u'The following components are provided under the Common Development and Distribution License 1.0. See project link for details.')\n",
      "(126, u'The following components are provided under the Common Development and Distribution License 1.1. See project link for details.')\n"
     ]
    }
   ],
   "source": [
    "def process_row(row):\n",
    "    row=row.strip()\n",
    "    return [ (len(row),(row)) ] if row else []\n",
    "\n",
    "file_rows=(sc.textFile(\"file:///home/ggomarr/.spark/NOTICE\")\n",
    "                      .flatMap(process_row))\n",
    "\n",
    "for r in file_rows.takeOrdered(5,key=lambda x: -x[0]):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Enjoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def translateFeature(feature,featureMap={'N':0,'Y':1,'NA':0,'BS':1,'MS':2,'PhD':3}):\n",
    "    try:\n",
    "        return int(feature)\n",
    "    except:\n",
    "        return featureMap[feature]\n",
    "def rephraseIntoLabeledPoint(features):\n",
    "    rephrasedFeatures=[translateFeature(feature) for feature in features]\n",
    "    return LabeledPoint(rephrasedFeatures[-1], array(rephrasedFeatures[:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rawData=sc.textFile(\"./misc/PastHires.csv\")\n",
    "header=rawData.first()\n",
    "trainingData=(rawData.filter(lambda x: x!=header)\n",
    "                     .map(lambda x: x.split(\",\"))\n",
    "                     .map(rephraseIntoLabeledPoint))\n",
    "model=DecisionTree.trainClassifier(trainingData, numClasses=2,\n",
    "                                     categoricalFeaturesInfo={1:2, 3:4, 4:2, 5:2},\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "testCandidates=[ array([10, 1, 3, 1, 0, 0])]\n",
    "testData=sc.parallelize(testCandidates)\n",
    "predictions = model.predict(testData).collect()\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 4 with 9 nodes\n",
      "  If (feature 1 in {0.0})\n",
      "   If (feature 5 in {0.0})\n",
      "    If (feature 0 <= 0.0)\n",
      "     If (feature 3 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 3 not in {1.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 0 > 0.0)\n",
      "     Predict: 0.0\n",
      "   Else (feature 5 not in {0.0})\n",
      "    Predict: 1.0\n",
      "  Else (feature 1 not in {0.0})\n",
      "   Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if stopSpark:\n",
    "    !/home/ggomarr/.spark/sbin/stop-slave.sh\n",
    "    !/home/ggomarr/.spark/sbin/stop-master.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
